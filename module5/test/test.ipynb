{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831e2e00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a40da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see init file in PySpark\n",
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession named test\n",
    "# local[*]: run Spark locally with as many worker threads as logical cores on local machine\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23813068-cec9-444b-b9a9-71c1e4a9439e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd52fff-8f97-4047-a8ed-1fbfe2b99c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download 1 Parquet file from url\n",
    "! wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d4fdc-b26d-41d7-8866-c4edfb73f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Parquet file\n",
    "df = spark.read.parquet(\"fhvhv_tripdata_2021-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test some Spark DataFrame attributes & methods\n",
    "# df.show(5)\n",
    "# df.head()\n",
    "# df.schema\n",
    "# df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ad2ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Writing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ea33f-56d1-46de-86b5-6482903bc012",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Writing to CSV file with 1000 first records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ae1eb-fbc0-405f-a889-145fa6cadaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 1000 first rows\n",
    "df_head = df.limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909298d-1efa-435f-90ee-8b14f9daee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to CSV file\n",
    "df_head.coalesce(1).write.option('header', 'true').mode('overwrite').csv('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84f7b8-5bb6-47d4-bec1-0e03ca418987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing whether file is saved successfully\n",
    "df_test = spark.read \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'true') \\\n",
    "    .csv(\"results/head.csv\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d47d6-bf6a-4ae9-b204-3c32764abce5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Saving to Parquet file (with partitioned data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c1ec3-89cd-4740-97d8-a4e24d0db414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"fhvhv_tripdata_2021-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc69146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide DataFrame into 24 partitions (each partition can be executed parallel)\n",
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed251553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write parquet files\n",
    "df.write.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1ff9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Transformation & Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Parquet files\n",
    "df = spark.read.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74044d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transformation & action\n",
    "df.select('pickup_datetime', 'dropoff_datetime', 'PUlocationID', 'DOlocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4aba34",
   "metadata": {},
   "source": [
    "### Functions & UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766347f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take dispatching_base_num and convert to hexa format\n",
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6322b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "crazy_stuff('B02884')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee00e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a UDF\n",
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "df = df \\\n",
    "    .withColumn('base_num_in_hex', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .select('base_num_in_hex', 'pickup_date', 'dropoff_date', 'PUlocationID', 'DOlocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9eb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test result\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eed0a04-722d-4401-bc3e-e33e560616d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop SparkSession\n",
    "if 'spark' in locals() and spark:\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
